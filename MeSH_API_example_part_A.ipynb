{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook illustrates how to use Ines' MTI_api_functions for annotating ChEMBL assay descriptions. This uses the Medical Text Indexer provided by the National Library of Medicine.\n",
    "\n",
    "More info here: https://ii.nlm.nih.gov/MTI/\n",
    "\n",
    "The steps in the example are as follows:\n",
    "\n",
    "1. Select assay descriptions from ChEMBL to create input files for the MeSH API (part A, this script)\n",
    "2. Submit assays using bsub to the EBI cluster in a job array (part A, this script)\n",
    "3. Redo any jobs that failed (part B, next script)\n",
    "4. Insert results from output text file into oracle tables (part C)\n",
    "\n",
    "There are three scripts(A, B and C) to cover these steps because the API jobs need to finish before doing the next part. I tested that these scripts work when executing them from the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as al\n",
    "import logging\n",
    "import MTI_api_functions as maf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Personal login details in correct format for sqlalchemy\n",
    "\n",
    "with open('/homes/ines/alchemy_ines_login.txt', 'r') as f:\n",
    "    engine = al.create_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', filename='./logs/heart_assays.log', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STEP 1 - Select assay descriptions from ChEMBL \n",
    "# For the purpose of this example, let's only do the assays that mention 'heart'\n",
    "\n",
    "my_assays = maf.get_assay_descriptions(engine, condition = \"lower(description) like '%heart%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 2 - Create input files for the MeSH API and place in directory containing subdirectories with the inputfiles\n",
    "# When I ran the whole of ChEMBL I used 4000 assays per inputfile and 100 files per subdirectory\n",
    "# The maximum number of files per subdirectory is 1000 because that's the max number of jobs per array\n",
    "\n",
    "maf.make_input_files(my_assays, nr_assays = 400, nr_files = 10, path_to_inputfiles = './heart_assays')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "to_api_dir = '/nfs/research2/jpo/shared/projects/HeCaToS/mesh_api/SKR_Web_API_V2_1'\n",
    "to_example_dir = '/nfs/research2/jpo/shared/projects/HeCaToS/mesh_api/SKR_Web_API_V2_1/examples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each subdirectory, submit a job array using bsub to EBI Cluster\n",
    "# Run only 2-3 subdirectories a time.. on advice from NLM as otherwise server is slowed down.\n",
    "\n",
    "for subdir in [item for item in os.listdir('./heart_assays') if not '.DS_Store' in item][:2]: # exclude invisible file, just doing two files here\n",
    "    maf.submit_job_array_for_inputdir(inputfiles_dir = 'heart_assays' , inputfiles_subdir=subdir, path_to_MTI_dir = to_api_dir, path_to_files_dir = to_example_dir, email = 'ines@ebi.ac.uk')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now need to wait for jobs to finish and I manually submitted each of the subdirectories after the previous one had finished.\n",
    "# See next script 'part B'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
